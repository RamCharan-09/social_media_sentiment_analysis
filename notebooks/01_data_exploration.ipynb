{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Social Media Sentiment Analysis - 45K Training\n",
    "## Working with Real Sentiment140 Dataset (1.6M â†’ 100K)\n",
    "\n",
    "This notebook will:\n",
    "1. Load 100,000 tweets from the full 1.6M dataset\n",
    "2. Clean and process the data\n",
    "3. Prepare for machine learning training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Social Media Sentiment Analysis - 100K Training\n",
      " All imports successful\n"
     ]
    }
   ],
   "source": [
    "#1: Setup and imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data.data_collector import DataCollector\n",
    "from src.data.data_cleaner import DataCleaner\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\" Social Media Sentiment Analysis - 100K Training\")\n",
    "print(\" All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2: Load 100K tweets\n",
    "collector = DataCollector()\n",
    "data = collector.load_data()\n",
    "\n",
    "if data is not None:\n",
    "    print(f\"\\n Dataset loaded successfully!\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "    print(f\"Memory: {data.memory_usage(deep=True).sum() / 1024**2:.1f}MB\")\n",
    "    \n",
    "    # Show sample tweets\n",
    "    print(f\"\\n Sample tweets:\")\n",
    "    for i in range(3):\n",
    "        sentiment = \"ðŸ˜¢ NEGATIVE\" if data.iloc[i]['sentiment'] == 0 else \"ðŸ˜Š POSITIVE\"\n",
    "        print(f\"{i+1}. {sentiment}: {data.iloc[i]['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: Complete cleaning pipeline\n",
    "print(\" Starting complete data cleaning pipeline...\")\n",
    "\n",
    "cleaner = DataCleaner()\n",
    "cleaned_data = cleaner.clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4: Show results\n",
    "if len(cleaned_data) > 0:\n",
    "    print(f\"\\n Pipeline complete!\")\n",
    "    \n",
    "    # Before/after examples\n",
    "    print(f\"\\n Before vs After cleaning:\")\n",
    "    for i in range(3):\n",
    "        print(f\"\\n{i+1}. ORIGINAL: {data.iloc[i]['text']}\")\n",
    "        print(f\"   CLEANED:  {cleaned_data.iloc[i]['cleaned_text']}\")\n",
    "        print(f\"   LABEL:    {cleaned_data.iloc[i]['sentiment_label']}\")\n",
    "    \n",
    "    # Statistics\n",
    "    original_avg = data['text'].str.len().mean()\n",
    "    cleaned_avg = cleaned_data['cleaned_text'].str.len().mean()\n",
    "    print(f\"\\n Text length: {original_avg:.1f} â†’ {cleaned_avg:.1f} chars\")\n",
    "    print(f\" Size reduction: {((original_avg-cleaned_avg)/original_avg*100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5: Visualize results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Sentiment distribution\n",
    "sentiment_counts = cleaned_data['sentiment_label'].value_counts()\n",
    "ax1.pie(sentiment_counts.values, labels=['ðŸ˜¢ Negative', 'ðŸ˜Š Positive'], \n",
    "        autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title(f'Sentiment Distribution\\n({len(cleaned_data):,} tweets)')\n",
    "\n",
    "# Text length distribution\n",
    "lengths = cleaned_data['cleaned_text'].str.len()\n",
    "ax2.hist(lengths, bins=30, alpha=0.7, color='skyblue')\n",
    "ax2.set_title('Tweet Length Distribution')\n",
    "ax2.set_xlabel('Characters')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Save processed data\n",
    "cleaner.save_data(cleaned_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
